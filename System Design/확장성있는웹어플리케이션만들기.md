# 확장성이 있는 어플리케이션 만들기

### 웹 분산 시스템 설계시의 고려사항

- 가용성 - 이중화, 분산 서버, single point of failure를 줄이자
- 성능 - 응답시간 줄이기, 트래픽 넘칠 경우 어떻게 할까?
- 신뢰성 - same input, same output 보장
- 확장성 - 더 많은 부하를 처리할 수 있도록. 추가적인 트래픽은 어떻게 처리할 수 있는지?
- 관리성 - 유지보수가 얼마나 쉬운가? 배포는 쉬운가?
- 비용 - HW, SW, 배포 관리 비용, 모든 비용



### 대규모 웹 어플리케이션에서 필요한 사항

Servies, 이중화, 분할, 예외처리 - 선택과 합의가 필요하다



### Servies

시스템을 상호 보완적인 서비스로 분할한다는 것 : 시스템을 기능 단위로 분리시키는 것

ex) 이미지 호스팅 애플리케이션의 경우, 이미지 업로드와 검색 기능은 각각의 서비스로 분리되는 것이 합리적



why? write와 read는 공유자원을 경쟁적으로 사용하기 때문이다.

읽기는 캐시의 도움을 받을 수 있지만, 쓰기는 결과적으로 디스크까지 도달해야한다.



또다른 잠재적문제는 동시 커넥션 수에 상한선이 있다.

읽기 요청 처리 수는 커넥션 수보다 많지만, 쓰기의 경우는 업로드 동안 연결을 열어 놓아야 한다.



시스템 아키텍쳐에는 정답은 없다. 트레이드 오프가 있을 뿐

읽기가 많은지 쓰기가 많은지, 둘 다 많은지, 질의가 데이터셋 전체에 대한 것인지, 부분에 대한 것인지, 정렬은 어떻게 할 것인지



### 이중화(Redundancy)

단일 고장점을 없애고, 장애 발생 시에도 백업하게 할 수 있거나, 시스템이 계송 동작할 수 있게 한다. (고가용성)

중요한 것은 shared nothing 아키텍쳐를 만드는 것 



### 파티션(Partitions)

하나의 서버에서 감당할 수 없는 많은 데이터가 있을 수 있다. 혹은 연산을 위해 많은 컴퓨팅 자원이 필요하게 되어 성능이 떨어지게 되는 경우도 있다. 

대안은 수직적 확장, 수평적 확장이다.

수직적 확장은 개개 서버의 자원을 추가하는 것. 더 빠른 cpu, 큰 용량의 메모리를 추가하는 것

수평적 확장은 노드를 추가하는 것. 데이터가 많을 경우 부분 데이터를 저장할 수 있는 노드를 추가

수평적 확장의 보편적인 방법 : 파티션, 샤드 단위로 분할



이미지를 저장하기 위해 사용하는 파일 서버를 여러 개로 할 수 있다. 이 설계에서는 이미지의 이름을 바탕으로 해당 이미지가 저장되어 있는 서버를 찾을 수 있는 방법이 필요. constitent hasing or increment id, id의 범위만 알면 접근 가능.



여러 서버에 데이터나 기능을 분산시킬 때의 이슈

1. 데이터 로컬리티 : 로컬에 있지 않을 수 있는 데이터를 얻기 위해 비용이 높은 네트워크를 이용한 읽기가 발생할 수 있어 잠재적인 성능 문제가 발생할 수 있음
2. 비정합성 : 읽기와 쓰기가 나눠져 있을 경우, 데이터 업데이트가 되려할 때, 읽기가 발생할 경우 리턴받는 데이터의 상태가 애매하다.



### 빠르고 확장성 있는 데이터 액세스를 위한 빌딩 블록

client - app server - db 구조의 경우를 생각해보자.

2가지 bottlenects 이 존재함. 

- app server에 대한 데이터 액세스
- db server에 대한 데이터 액세스

app server에 대한 데이터 액세스의 확장성 있는 설계에서는 웹 서버는 최소화되고, or shared-nothing 아키텍처를 가진다. 수평적 확장이 가능해진다.



데이터 액세스와 확장성을 위해 사용하는 일반적인 전략과 방법

 (성능에 가장 영향을 미치는 것은 DISK I/O)

- 캐시, 프록시, 인덱스, 로드 밸런서



#### 캐시

- LRU 알고리즘에 기반한 방법
- 짧은 시간 동안 유지되는 메모리
- 데이터 저장소보다 매우 빠르고 자주 액세스되는 데이터를 보유
- 보통 프론트엔드와 가까운 곳에 위치하는 경우가 많다.



그렇다면 캐시를 어디서 사용하는가?

1. Request Node에서 캐시 사용

USER - REQUEST -> Request Node -> Data

Request Node에서 캐시 사용. 요청 노드에 데이터가 존재하면, 로컬에서 캐싱된 데이터를 보내고, 없으면 디스크에 데이터 질의

-> 요청 노드를 여러 개로 확장한다면 ? 각각의 요청 노드에서 각각의 캐시를 가지게 됨. 만약 로드 밸런서가 임의로 요청을 분산시키면, 같은 요청이 다른 노드로 가게 될 수도 있다. (캐시 미스 증가)

-> 어떻게 해결? 전역 캐시와 분산 캐시



2. 전역 캐시

  2가지 아키텍쳐가 있다.

- 캐시가 검색을 책임지는 전역캐시 (캐시에 확인, 없으면 캐시에서 디스크 검색 후 응답)
  - 대부분 이 아키텍쳐를 선호 (요청이 적다.)

- 요청 노드가 검색을 하는 전역 캐시 (캐시에 먼저 확인, 없으면 디스크 접근, 요청 여러번 발생)
  - 정적 파일을 캐시에 저장하는 경우 (이때, 정적파일은 절대 캐시에서 지워지지 않음)

3. 분산 캐시

- 각각의 노드가 캐시 데이터를 갖는 방식
- consistent hasing 함수 사용
- 요청이 들어오면 원본 저장 공간으로 요청을 보내기 전에 다른 노드에 요청을 보냄
- 전체 캐시 크기를 증가시킬 수 있음
- 단점은 장애가 발생한 노드를 처리하는 방법이 필요하다.
  - 다른 노드에 여러 개의 복제본을 가지는 방법으로 해결하기도 함



#### 프록시

- 클라이언트의 요청을 백엔드 서버에 전달하는 중간  HW/SW
- 요청을 필터링, 로깅, 변환(암/복호화, 압축)하는데 사용
- 여러 서버에서 오는 요청을 받아 정리하여, 전체 시스템 관점에서 요청 트래픽을 최적화
- 프록시와 캐시를 함께 사용할 경우 캐시를 프록시 앞에 두는 것이 최선이다.



#### 인덱스

- 데이터베이스에서 데이터를 빨리 찾기 위한 색인



#### 로드 밸런서

- 서비스 요청을 여러 노드에게 분배하는 일을 한다
- 노드를 추가하는 것만으로 서비스가 확장성을 가질 수 있게 한다.
- 프록시처럼 요청의 종류를 파악하고 해당 요청을 처리할 수 있는 노드에 전달하는 기능을 가짐



#### 큐(Queues)

- task가 들어오면, 큐에 쌓이고, 워커가 일을 처리할 수 있는 상황이 되면 큐에서 꺼내여 처리

- 일을 비동기적으로 처리할 수 있게 한다.

